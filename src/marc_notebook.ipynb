{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Marc Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) import usefuls module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math \n",
    "\n",
    "from itertools import groupby\n",
    "from helpers import *\n",
    "\n",
    "from opt_helpers_marc import *\n",
    "from plots import *\n",
    "import scipy\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items: 10000, number of users: 1000\n"
     ]
    }
   ],
   "source": [
    "# write here the path to the dataset\n",
    "path_dataset = \"../datasets/data_train.csv\"\n",
    "\n",
    "# load the data \n",
    "ratings = load_data(path_dataset)\n",
    "ratings = ratings.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Split the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First get the numbers of ratings per user and ratings per film \n",
    "# And plot these values\n",
    "\n",
    "#num_items_per_user, num_users_per_item = plot_raw_data(ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data split done\n"
     ]
    }
   ],
   "source": [
    "# fraction of the data set that will be the test set \n",
    "p_test = 0.5\n",
    "\n",
    "train, test = opt_split_data(ratings, p_test)\n",
    "print(\"data split done\")\n",
    "# plot the resulting training and test set \n",
    "#valid_ratings = valid_ratings[:100,:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[100,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1000)\n",
      "(5, 10000)\n",
      "initialization of the factorization : done\n",
      "learn the matrix factorization using SGD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Marc/Documents/cours/EPFL/etudes/codes/python_notebooks/CS-433/PCML_project2/src/opt_helpers_marc.py:227: RuntimeWarning: overflow encountered in multiply\n",
      "  # store the new values of the features of d in an auxiliary variable\n",
      "/Users/Marc/Documents/cours/EPFL/etudes/codes/python_notebooks/CS-433/PCML_project2/src/opt_helpers_marc.py:232: RuntimeWarning: overflow encountered in multiply\n",
      "  \n",
      "/Users/Marc/Documents/cours/EPFL/etudes/codes/python_notebooks/CS-433/PCML_project2/src/opt_helpers_marc.py:235: RuntimeWarning: invalid value encountered in subtract\n",
      "  item_features[:,d] = aux\n",
      "/Users/Marc/Documents/cours/EPFL/etudes/codes/python_notebooks/CS-433/PCML_project2/src/opt_helpers_marc.py:229: RuntimeWarning: invalid value encountered in subtract\n",
      "  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-073fa3faafa2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmse_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt_matrix_factorization_SGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_user\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_item\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Marc/Documents/cours/EPFL/etudes/codes/python_notebooks/CS-433/PCML_project2/src/opt_helpers_marc.py\u001b[0m in \u001b[0;36mopt_matrix_factorization_SGD\u001b[0;34m(train, test, K, num_epochs, lambda_user, lambda_item, gamma)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0;31m# compute the gradient associated to the user n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0mgradu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mitem_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlambda_user\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0muser_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;31m# update the features of n and the features of d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "K = 5\n",
    "num_epochs = 30\n",
    "lambda_user = 1e-6\n",
    "lambda_item = 1e-6\n",
    "gamma = 0.1\n",
    "\n",
    "items, users, rmse_test = opt_matrix_factorization_SGD(train, test, K, num_epochs, lambda_user, lambda_item, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Matrix Factorization through Stochastic Gradient Descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix factorization for the number of features :  2\n",
      "0.00025025025025\n",
      "learn the matrix factorization using SGD...\n",
      "iter: 0, RMSE on training set: 1.5223792661766111.\n",
      "RMSE on test data: 1.5343891428465641.\n",
      "best number of features found :  2\n",
      "rmse on the test set for this number of features :  1.5343891428465641\n"
     ]
    }
   ],
   "source": [
    "## Perform matrix factorization through stochastic gradient descent, for different numbers of features\n",
    "# (grid search on the number of feature)\n",
    "# keep the best number of feature, and the associated factorization\n",
    "\n",
    "## Parameters for the matrix factorization\n",
    "# maximum number of features fixed\n",
    "max_K = 3\n",
    "\n",
    "# incrementation step for K\n",
    "step_K = 2\n",
    "\n",
    "# number of full iterations of the stochastic gradient descent\n",
    "max_epochs = 1\n",
    "\n",
    "# regularization parameters (regularization of the loss function in Gradient Descent)\n",
    "lambda_user = 1e-4\n",
    "lambda_item = 1e-4\n",
    "\n",
    "# descent step size\n",
    "gamma = 0.1\n",
    "\n",
    "# initialization of variables refering to the matrix factorization for the best number\n",
    "best_rmse_test_sgd = float('Inf')\n",
    "best_k_sgd = 0\n",
    "best_user_feat_sgd = np.zeros(1)\n",
    "best_item_feat_sgd = np.zeros(1)\n",
    "\n",
    "# for each K of the grid, compute the matrix factorization (training set) and the rmse (test set), \n",
    "# If it improves the results, update the rmse\n",
    "\n",
    "for K in range(2,max_K,step_K):\n",
    "    \n",
    "    print(\"matrix factorization for the number of features : \", K)\n",
    "    \n",
    "    # compute the stochastic gradient descent matrix factorization\n",
    "    user_features, item_features, rmse_test = matrix_factorization_SGD(train, test, K, max_epochs, lambda_user, lambda_item, gamma)\n",
    "    if rmse_test < best_rmse_test_sgd:\n",
    "        # better rmse => update the references\n",
    "        best_rmse_test_sgd = rmse_test\n",
    "        best_k_sgd = K\n",
    "        best_user_feat_sgd = user_features\n",
    "        best_item_feat_sgd = item_features\n",
    "\n",
    "# print the results\n",
    "print(\"best number of features found : \", best_k_sgd)\n",
    "print(\"rmse on the test set for this number of features : \", best_rmse_test_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction matrix [[ 3.94668896  3.99877292  2.93442447  2.95974889  1.97894177  4.47962859\n",
      "   3.94782554  3.97598334  2.83815264  2.79078221]\n",
      " [ 3.99983284  4.07341087  2.98389335  2.99959159  2.01191343  4.61382112\n",
      "   4.00197101  4.0288096   3.21693447  2.85966532]\n",
      " [ 3.99979547  4.03150033  2.96381688  2.99958695  1.99915864  4.46501351\n",
      "   3.99994743  4.03020596  2.53107347  2.79659845]\n",
      " [ 4.00025042  4.18063763  3.03534155  2.99984508  2.04460837  4.99374712\n",
      "   4.00745484  4.02557257  4.96657647  3.02075642]\n",
      " [ 3.99962516  4.0308356   2.9634546   2.99945951  1.99892354  4.46307162\n",
      "   3.99975373  4.03005125  2.5228897   2.79573705]\n",
      " [ 4.00045826  4.18249796  3.03628598  3.00000002  2.04521438  4.99984425\n",
      "   4.00774099  4.02572545  4.99374727  3.02338713]\n",
      " [ 3.99925881  4.12844171  3.01009385  2.99913004  2.02854077  4.81074943\n",
      "   4.00403474  4.02632675  4.12740013  2.94298545]\n",
      " [ 3.99996204  4.18123877  3.03555486  2.99962831  2.04473549  4.9965936\n",
      "   4.00720875  4.02525145  4.98100091  3.02189743]\n",
      " [ 3.90362754  3.9130962   2.88227547  2.92747924  1.94456091  4.28136775\n",
      "   3.90275726  3.93404229  2.11849627  2.69702969]\n",
      " [ 4.00028636  4.14353635  3.0175867   2.99989278  2.03333054  4.86184514\n",
      "   4.0057292   4.02688064  4.35832255  2.96487004]]\n"
     ]
    }
   ],
   "source": [
    "# new test cell\n",
    "predict = np.dot(np.transpose(best_user_feat_sgd),best_item_feat_sgd)\n",
    "print(\"prediction matrix\", predict[:10,:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5) Matrix Factorization Using alternative Least Square Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4065f93d19cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mbest_rmse_test_als\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mbest_k_als\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mbest_user_feat_als\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mbest_item_feat_als\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "## Perform matrix factorization through stochastic gradient descent, for different numbers of features\n",
    "# (grid search on the number of feature)\n",
    "# keep the best number of feature, and the associated factorization\n",
    "\n",
    "## Parameters for the matrix factorization\n",
    "# maximum number of features fixed\n",
    "max_K = 6\n",
    "\n",
    "# incrementation step for K\n",
    "step_K = 1\n",
    "\n",
    "# regularization parameters for the loss function \n",
    "lambda_user = 1e-8\n",
    "lambda_item = 1e-8\n",
    "\n",
    "# stop criterion\n",
    "stop_criterion = 1e-3\n",
    "\n",
    "# number of iterations of the alternative least squares method \n",
    "it_max = 10\n",
    "\n",
    "# initialization of variables refering to the matrix factorization for the best number\n",
    "best_rmse_test_als = float('Inf')\n",
    "best_k_als = 0\n",
    "best_user_feat_als = np.zeros(1)\n",
    "best_item_feat_als = np.zeros(1)\n",
    "\n",
    "for K in range(1,max_K,step_K):\n",
    "    \n",
    "    print(\"als matrix factorization for the number of features : \", K)\n",
    "    \n",
    "    # compute the matrix factorization using alternative least squares method\n",
    "    user_features, item_features, rmse_test =ALS(train, test,K, lambda_user, lambda_item, stop_criterion, it_max)\n",
    "    print(\"rmse on test data for \", K, \" features : \", rmse_test)\n",
    "    if rmse_test < best_rmse_test_als:\n",
    "        # better rmse => update the references\n",
    "        best_rmse_test_als = rmse_test\n",
    "        best_k_als = K\n",
    "        best_user_feat_als = user_features\n",
    "        best_item_feat_als = item_features\n",
    "        \n",
    "# print the results\n",
    "print(\"best number of features found : \", best_k_als)\n",
    "print(\"rmse on the test set for this number of features : \", best_rmse_test_als)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Prediction using SGD Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items: 10000, number of users: 1000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAAEbCAYAAABgLnslAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\np2RxI+U4juOULG6kHMdxnJLl/wORWjD2+n+v7wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a50e3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "### Prediction using the SGD Matrix Factorization best parameters found previously \n",
    "\n",
    "# load the submission data set \n",
    "# write here the path to the dataset\n",
    "path_dataset_submit = \"../datasets/sampleSubmission.csv\"\n",
    "\n",
    "# load the data \n",
    "ratings_submit = load_data(path_dataset_submit)\n",
    "num_items_per_user, num_users_per_item = plot_raw_data(ratings_submit)\n",
    "\n",
    "#ratings_submit = ratings_submit[:30,:50]\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "# Need to apply the same transformation and keep only in the training set the items,users for which there are at least\n",
    "# a certain amount of information => train_submit : FALSE => UNCOMPATIBLE SHAPE\n",
    "#min_num_ratings = 10\n",
    "#dummy_valid_ratings_submit, train_submit, dummy_test_submit = split_data(ratings_submit, num_items_per_user, num_users_per_item, min_num_ratings, 0)\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d,n : 10000 1000\n",
      "learn the matrix factorization using SGD...\n",
      "iter: 0, RMSE on training set: 0.04511382239508148.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-745cc5e6fdef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# compute the prediction matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# => directly use the ratings matrix as rating as training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0muser_features_submit_sgd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_features_submit_sgd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmse_full_ratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatrix_factorization_SGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratings_submit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratings_submit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_k_sgd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_user\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_item\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# print : rmse of our full prediction :\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Marc/Documents/cours/EPFL/etudes/codes/python_notebooks/CS-433/PCML_project2/src/helpers_marc.py\u001b[0m in \u001b[0;36mmatrix_factorization_SGD\u001b[0;34m(train, test, K, num_epochs, lambda_user, lambda_item, gamma)\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0mnew_item_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_item_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgradi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;31m# updating z[k,n]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                 \u001b[0mgradu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mitem_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlambda_user\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0muser_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m                 \u001b[0mnew_user_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_user_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgradu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Marc/anaconda/lib/python3.5/site-packages/scipy/sparse/lil.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    239\u001b[0m                 v = _csparsetools.lil_get1(self.shape[0], self.shape[1],\n\u001b[1;32m    240\u001b[0m                                            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                                            i, j)\n\u001b[0m\u001b[1;32m    242\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# SAME PARAMETERS AS DURING THE TRAINING\n",
    "# number of full iterations of the stochastic gradient descent\n",
    "max_epochs =20\n",
    "\n",
    "# regularization parameters (regularization of the loss function in Gradient Descent)\n",
    "lambda_user = 1e-3\n",
    "lambda_item = 1e-7\n",
    "\n",
    "# descent step size\n",
    "gamma = 0.1\n",
    "#ratings_submit = ratings_submit[:1000,:1000]\n",
    "# size of the rating matrix\n",
    "d,n = ratings_submit.shape\n",
    "print(\"d,n :\", d,n)\n",
    "# for test only \n",
    "best_k_sgd = 5\n",
    "\n",
    "# compute the prediction matrix \n",
    "# => directly use the ratings matrix as rating as training set \n",
    "user_features_submit_sgd, item_features_submit_sgd, rmse_full_ratings = matrix_factorization_SGD(ratings_submit, ratings_submit, best_k_sgd, max_epochs, lambda_user, lambda_item, gamma)\n",
    "\n",
    "# print : rmse of our full prediction : \n",
    "print(\"rmse of our prediction : \", rmse_full_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
