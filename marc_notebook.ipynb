{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Marc Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) import usefuls module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math \n",
    "\n",
    "from itertools import groupby\n",
    "from helpers import *\n",
    "\n",
    "from opt_helpers_marc import *\n",
    "from plots import *\n",
    "import scipy\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items: 10000, number of users: 1000\n"
     ]
    }
   ],
   "source": [
    "# write here the path to the dataset\n",
    "path_dataset = \"datasets/data_train.csv\"\n",
    "\n",
    "# load the data \n",
    "ratings = load_data(path_dataset)\n",
    "ratings = ratings.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Split the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data split done\n"
     ]
    }
   ],
   "source": [
    "# fraction of the data set that will be the test set \n",
    "p_test = 0.5\n",
    "\n",
    "train, test = opt_split_data(ratings, p_test)\n",
    "print(\"data split done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First test of matrix factorization : overflow ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization of the factorization : done\n",
      "learn the matrix factorization using SGD...\n",
      "iter: 0, RMSE on training set: 1.76396297262.\n",
      "iter: 1, RMSE on training set: 1.64196096825.\n",
      "iter: 2, RMSE on training set: 1.56605146636.\n",
      "iter: 3, RMSE on training set: 1.52577419967.\n",
      "iter: 4, RMSE on training set: 1.48270209707.\n",
      "iter: 5, RMSE on training set: 1.45362480025.\n",
      "iter: 6, RMSE on training set: 1.43931128142.\n",
      "iter: 7, RMSE on training set: 1.42130140107.\n",
      "iter: 8, RMSE on training set: 1.41263053146.\n",
      "iter: 9, RMSE on training set: 1.39873461433.\n",
      "iter: 10, RMSE on training set: 1.39329548055.\n",
      "iter: 11, RMSE on training set: 1.38688689686.\n",
      "iter: 12, RMSE on training set: 1.38239702643.\n",
      "iter: 13, RMSE on training set: 1.37851341262.\n",
      "iter: 14, RMSE on training set: 1.37530305555.\n",
      "iter: 15, RMSE on training set: 1.37291351833.\n",
      "iter: 16, RMSE on training set: 1.37099876241.\n",
      "iter: 17, RMSE on training set: 1.36987847865.\n",
      "iter: 18, RMSE on training set: 1.36852726726.\n",
      "iter: 19, RMSE on training set: 1.36742121387.\n",
      "iter: 20, RMSE on training set: 1.36679819134.\n",
      "iter: 21, RMSE on training set: 1.36625643467.\n",
      "iter: 22, RMSE on training set: 1.36596460699.\n",
      "iter: 23, RMSE on training set: 1.3654244248.\n",
      "iter: 24, RMSE on training set: 1.36542573754.\n",
      "iter: 25, RMSE on training set: 1.36558484096.\n",
      "iter: 26, RMSE on training set: 1.36541020871.\n",
      "iter: 27, RMSE on training set: 1.36674834031.\n",
      "iter: 28, RMSE on training set: 1.37197016474.\n",
      "iter: 29, RMSE on training set: 1.37957863406.\n",
      "iter: 30, RMSE on training set: 1.38387686531.\n",
      "iter: 31, RMSE on training set: 1.38547247439.\n",
      "iter: 32, RMSE on training set: 1.38801436265.\n",
      "iter: 33, RMSE on training set: 1.39446227408.\n",
      "iter: 34, RMSE on training set: 1.41176799569.\n",
      "iter: 35, RMSE on training set: 1.43292639085.\n",
      "iter: 36, RMSE on training set: 1.44680082156.\n",
      "iter: 37, RMSE on training set: 1.45397827805.\n",
      "iter: 38, RMSE on training set: 1.45518640925.\n",
      "iter: 39, RMSE on training set: 1.45519282201.\n",
      "RMSE on test data: 1.50845483831.\n"
     ]
    }
   ],
   "source": [
    "K = 10\n",
    "num_epochs = 40\n",
    "lambda_user = 1e-7\n",
    "lambda_item = 1e-7\n",
    "gamma = 0.1\n",
    "\n",
    "items, users, rmse_test = opt_matrix_factorization_SGD(train, test, K, num_epochs, lambda_user, lambda_item, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Matrix Factorization through Stochastic Gradient Descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Perform matrix factorization through stochastic gradient descent, for different numbers of features\n",
    "# (grid search on the number of feature)\n",
    "# keep the best number of feature, and the associated factorization\n",
    "\n",
    "## Parameters for the matrix factorization\n",
    "# maximum number of features fixed\n",
    "max_K = 15\n",
    "\n",
    "# incrementation step for K\n",
    "step_K = 2\n",
    "\n",
    "# number of full iterations of the stochastic gradient descent\n",
    "max_epochs = 10\n",
    "\n",
    "# regularization parameters (regularization of the loss function in Gradient Descent)\n",
    "lambda_user = 1e-3\n",
    "lambda_item = 1e-3\n",
    "\n",
    "# descent step size\n",
    "gamma = 0.1\n",
    "\n",
    "# initialization of variables refering to the matrix factorization for the best number\n",
    "best_rmse_test_sgd = float('Inf')\n",
    "best_k_sgd = 0\n",
    "best_user_feat_sgd = np.zeros(1)\n",
    "best_item_feat_sgd = np.zeros(1)\n",
    "\n",
    "# for each K of the grid, compute the matrix factorization (training set) and the rmse (test set), \n",
    "# If it improves the results, update the rmse\n",
    "\n",
    "for K in range(1,max_K,step_K):\n",
    "    \n",
    "    print(\"matrix factorization for the number of features : \", K)\n",
    "    \n",
    "    # compute the stochastic gradient descent matrix factorization\n",
    "    user_features, item_features, rmse_test = matrix_factorization_SGD(train, test, K, max_epochs, lambda_user, lambda_item, gamma)\n",
    "    if rmse_test < best_rmse_test_sgd:\n",
    "        # better rmse => update the references\n",
    "        best_rmse_test_sgd = rmse_test\n",
    "        best_k_sgd = K\n",
    "        best_user_feat_sgd = user_features\n",
    "        best_item_feat_sgd = item_features\n",
    "\n",
    "# print the results\n",
    "print(\"best number of features found : \", best_k_sgd)\n",
    "print(\"rmse on the test set for this number of features : \", best_rmse_test_sgd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5) Matrix Factorization Using alternative Least Square Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Perform matrix factorization through stochastic gradient descent, for different numbers of features\n",
    "# (grid search on the number of feature)\n",
    "# keep the best number of feature, and the associated factorization\n",
    "\n",
    "## Parameters for the matrix factorization\n",
    "# maximum number of features fixed\n",
    "max_K = 6\n",
    "\n",
    "# incrementation step for K\n",
    "step_K = 1\n",
    "\n",
    "# regularization parameters for the loss function \n",
    "lambda_user = 1e-8\n",
    "lambda_item = 1e-8\n",
    "\n",
    "# stop criterion\n",
    "stop_criterion = 1e-3\n",
    "\n",
    "# number of iterations of the alternative least squares method \n",
    "it_max = 10\n",
    "\n",
    "# initialization of variables refering to the matrix factorization for the best number\n",
    "best_rmse_test_als = float('Inf')\n",
    "best_k_als = 0\n",
    "best_user_feat_als = np.zeros(1)\n",
    "best_item_feat_als = np.zeros(1)\n",
    "\n",
    "for K in range(1,max_K,step_K):\n",
    "    \n",
    "    print(\"als matrix factorization for the number of features : \", K)\n",
    "    \n",
    "    # compute the matrix factorization using alternative least squares method\n",
    "    user_features, item_features, rmse_test =ALS(train, test,K, lambda_user, lambda_item, stop_criterion, it_max)\n",
    "    print(\"rmse on test data for \", K, \" features : \", rmse_test)\n",
    "    if rmse_test < best_rmse_test_als:\n",
    "        # better rmse => update the references\n",
    "        best_rmse_test_als = rmse_test\n",
    "        best_k_als = K\n",
    "        best_user_feat_als = user_features\n",
    "        best_item_feat_als = item_features\n",
    "        \n",
    "# print the results\n",
    "print(\"best number of features found : \", best_k_als)\n",
    "print(\"rmse on the test set for this number of features : \", best_rmse_test_als)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Prediction using SGD Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Prediction using the SGD Matrix Factorization best parameters found previously \n",
    "\n",
    "# load the submission data set \n",
    "# write here the path to the dataset\n",
    "path_dataset_submit = \"../datasets/sampleSubmission.csv\"\n",
    "\n",
    "# load the data \n",
    "ratings_submit = load_data(path_dataset_submit)\n",
    "num_items_per_user, num_users_per_item = plot_raw_data(ratings_submit)\n",
    "\n",
    "#ratings_submit = ratings_submit[:30,:50]\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Need to apply the same transformation and keep only in the training set the items,users for which there are at least\n",
    "# a certain amount of information => train_submit : FALSE => UNCOMPATIBLE SHAPE\n",
    "#min_num_ratings = 10\n",
    "#dummy_valid_ratings_submit, train_submit, dummy_test_submit = split_data(ratings_submit, num_items_per_user, num_users_per_item, min_num_ratings, 0)\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SAME PARAMETERS AS DURING THE TRAINING\n",
    "# number of full iterations of the stochastic gradient descent\n",
    "max_epochs =20\n",
    "\n",
    "# regularization parameters (regularization of the loss function in Gradient Descent)\n",
    "lambda_user = 1e-3\n",
    "lambda_item = 1e-7\n",
    "\n",
    "# descent step size\n",
    "gamma = 0.1\n",
    "#ratings_submit = ratings_submit[:1000,:1000]\n",
    "# size of the rating matrix\n",
    "d,n = ratings_submit.shape\n",
    "print(\"d,n :\", d,n)\n",
    "# for test only \n",
    "best_k_sgd = 5\n",
    "\n",
    "# compute the prediction matrix \n",
    "# => directly use the ratings matrix as rating as training set \n",
    "user_features_submit_sgd, item_features_submit_sgd, rmse_full_ratings = matrix_factorization_SGD(ratings_submit, ratings_submit, best_k_sgd, max_epochs, lambda_user, lambda_item, gamma)\n",
    "\n",
    "# print : rmse of our full prediction : \n",
    "print(\"rmse of our prediction : \", rmse_full_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
